# ğŸ›°ï¸ SRGAN for Optimised Satellite Imagery Upscaling

A complete, production-ready implementation of **Super-Resolution Generative Adversarial Network (SRGAN)** for 4Ã— upscaling of satellite imagery. This project includes training pipeline, REST API, and modern web frontend.

## ğŸ¯ Project Overview

This system converts low-resolution satellite images (64Ã—64) into high-resolution images (256Ã—256) using deep learning, achieving superior perceptual quality compared to traditional interpolation methods.

### Key Features

- âœ… **Deep Residual Generator** (SRResNet-based) with 16 residual blocks
- âœ… **CNN Discriminator** for adversarial training
- âœ… **VGG19 Perceptual Loss** for realistic textures
- âœ… **Adversarial + MSE Loss** for optimal training
- âœ… **FastAPI REST API** for production deployment
- âœ… **Next.js Frontend** with dark theme and animations
- âœ… **Google Colab Support** for free GPU training
- âœ… **Comprehensive Evaluation** (PSNR, SSIM, visual comparisons)

## ğŸ“ Project Structure

```
SRGAN-Satellite/
â”‚
â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py            # REST API server
â”‚   â””â”€â”€ requirements.txt   # API dependencies
â”‚
â”œâ”€â”€ frontend-next/         # Next.js frontend
â”‚   â”œâ”€â”€ app/              # Next.js app directory
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â””â”€â”€ package.json      # Frontend dependencies
â”‚
â”œâ”€â”€ colab/                 # Google Colab notebooks
â”‚   â””â”€â”€ SRGAN_Training.ipynb
â”‚
â”œâ”€â”€ data/                  # Dataset handling
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ degradation.py
â”‚   â””â”€â”€ download_dataset.py
â”‚
â”œâ”€â”€ models/                # Neural networks
â”‚   â”œâ”€â”€ generator.py
â”‚   â””â”€â”€ discriminator.py
â”‚
â”œâ”€â”€ train/                 # Training scripts
â”‚   â”œâ”€â”€ pretrain_generator.py
â”‚   â””â”€â”€ train_srgan.py
â”‚
â”œâ”€â”€ evaluate/             # Evaluation
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ evaluate.py
â”‚
â”œâ”€â”€ inference/            # Inference
â”‚   â””â”€â”€ upscale_image.py
â”‚
â”œâ”€â”€ loss/                 # Loss functions
â”‚   â””â”€â”€ vgg_loss.py
â”‚
â”œâ”€â”€ utils/                # Utilities
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ main.py               # CLI entry point
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone <your-repo-url>
cd SRGAN-Satellite

# Install Python dependencies
pip install -r requirements.txt

# Install API dependencies
pip install -r api/requirements.txt

# Install frontend dependencies
cd frontend-next
npm install
cd ..
```

### 2. Download Dataset

```bash
# Download DIV2K (recommended)
python main.py download-dataset --dataset div2k --auto-config

# Or UC Merced (satellite-specific)
python main.py download-dataset --dataset ucmerced --auto-config
```

### 3. Training

#### Option A: Local Training

```bash
# Pre-train generator
python main.py pretrain

# Train SRGAN (automatic continuation)
python main.py train --pretrained checkpoints/generator_pretrained_final.pth
```

#### Option B: Google Colab (Free GPU)

1. Upload `colab/SRGAN_Training.ipynb` to Google Colab
2. Run cells sequentially
3. Training runs on free GPU (T4/V100)

### 4. Evaluation

```bash
python main.py evaluate --model checkpoints/generator_final.pth
```

### 5. Start Services

#### Backend API

```bash
cd api
python main.py
# API runs on http://localhost:8000
```

#### Frontend

```bash
cd frontend-next
npm run dev
# Frontend runs on http://localhost:3000
```

## ğŸ—ï¸ Architecture

### Generator (SRResNet-based)

- **Input**: 64Ã—64Ã—3 (LR image)
- **Architecture**:
  - Initial Conv (9Ã—9, 64 features)
  - 16 Residual Blocks (Conv â†’ BN â†’ PReLU â†’ Conv â†’ BN)
  - Post-residual processing
  - 2Ã— Upsample Block (PixelShuffle)
  - 2Ã— Upsample Block (PixelShuffle)
  - Output Conv (9Ã—9, 3 channels)
- **Output**: 256Ã—256Ã—3 (HR image)
- **Parameters**: 1,546,774

### Discriminator

- **Input**: 256Ã—256Ã—3 (HR image)
- **Architecture**:
  - Progressive feature extraction (64 â†’ 128 â†’ 256 â†’ 512)
  - Strided convolutions for downsampling
  - Global average pooling
  - Fully connected layers (512 â†’ 1024 â†’ 1)
- **Output**: Probability (0-1)
- **Parameters**: 5,213,505

### Loss Function

```
L_total = L_VGG + 10â»Â³ Ã— L_GAN + L_MSE
```

- **L_VGG**: VGG19 perceptual loss (weight: 1.0)
- **L_GAN**: Adversarial loss (weight: 10â»Â³)
- **L_MSE**: Pixel MSE loss (weight: 1.0)

## ğŸ“Š Training Strategy

### Phase 1: Pre-training (MSE Only)

- **Purpose**: Stabilize generator weights
- **Loss**: MSE only
- **Epochs**: 1-100 (configurable)
- **Time**: ~10-60 minutes (depends on dataset size)

### Phase 2: Adversarial Training

- **Purpose**: Fine-tune with full loss
- **Loss**: VGG + GAN + MSE
- **Epochs**: 1-200 (configurable)
- **Time**: ~10-120 minutes

## ğŸ¨ Frontend Features

- ğŸŒ™ **Dark Theme** with gradient accents
- âœ¨ **Framer Motion** animations
- ğŸ–¼ï¸ **Before/After Slider** for comparison
- ğŸ“Š **Metrics Dashboard** (PSNR, SSIM)
- ğŸ—ï¸ **Architecture Visualization**
- ğŸ“š **Dataset Explanation** page
- ğŸ“¤ **Drag & Drop** image upload
- âš¡ **Real-time Processing**

## ğŸ”Œ API Endpoints

### `GET /api/health`
Health check endpoint

### `GET /api/model/info`
Get model information and status

### `POST /api/upscale`
Upscale an image
- **Request**: Multipart form with image file
- **Response**: JSON with upscaled image (base64) and metrics

### `GET /api/metrics`
Get training evaluation metrics

## ğŸ“ˆ Evaluation Metrics

- **PSNR** (Peak Signal-to-Noise Ratio): Pixel-level accuracy
- **SSIM** (Structural Similarity Index): Perceptual quality
- **Visual Comparisons**: Side-by-side with bicubic baseline

## ğŸ› ï¸ Configuration

Edit `utils/config.py` to customize:

- Dataset paths
- Model architecture (residual blocks, features)
- Training hyperparameters (batch size, epochs, learning rates)
- Loss weights
- Device (CPU/GPU)

## ğŸ“¦ Datasets

### DIV2K (Recommended)
- **Size**: 900 images (800 train + 100 val)
- **Quality**: Very High
- **Download**: `python main.py download-dataset --dataset div2k`

### UC Merced
- **Size**: 2,100 satellite images
- **Quality**: High
- **Download**: `python main.py download-dataset --dataset ucmerced`

## ğŸ“ Academic Use

This project is designed for:
- âœ… College project submissions
- âœ… Viva presentations
- âœ… Research papers
- âœ… Portfolio showcase

### Key Highlights for Viva

1. **Complete Implementation**: End-to-end system
2. **Research-Grade Code**: Well-commented, modular
3. **Modern Stack**: PyTorch, FastAPI, Next.js
4. **Production-Ready**: REST API, web interface
5. **Comprehensive Documentation**: README, code comments

## ğŸš€ Deployment

### Local Development

```bash
# Terminal 1: API
cd api && python main.py

# Terminal 2: Frontend
cd frontend-next && npm run dev
```

### Production

```bash
# Build frontend
cd frontend-next
npm run build
npm start

# Run API with uvicorn
cd api
uvicorn main:app --host 0.0.0.0 --port 8000
```

## ğŸ“ License

This project is provided for academic and research purposes.

## ğŸ‘¥ Credits

Built as a complete, production-ready implementation for satellite imagery super-resolution, suitable for academic evaluation and research applications.

---

**For questions or issues, please refer to the documentation or open an issue.**
